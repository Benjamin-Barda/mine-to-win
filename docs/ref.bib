@article{arxiv:FastRCNN,
  author    = {Ross B. Girshick},
  title     = {Fast {R-CNN}},
  journal   = {CoRR},
  volume    = {abs/1504.08083},
  year      = {2015},
  url       = {http://arxiv.org/abs/1504.08083},
  eprinttype = {arXiv},
  eprint    = {1504.08083},
  timestamp = {Mon, 13 Aug 2018 16:49:11 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/Girshick15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{arxiv:FasterRCNN,
  author    = {Shaoqing Ren and
               Kaiming He and
               Ross B. Girshick and
               Jian Sun},
  title     = {Faster {R-CNN:} Towards Real-Time Object Detection with Region Proposal
               Networks},
  journal   = {CoRR},
  volume    = {abs/1506.01497},
  year      = {2015},
  url       = {http://arxiv.org/abs/1506.01497},
  eprinttype = {arXiv},
  eprint    = {1506.01497},
  timestamp = {Mon, 13 Aug 2018 16:46:02 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/RenHG015.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Lowe:SIFT,
  abstract = {This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.},
  acmid = {996342},
  added-at = {2012-11-08T15:54:11.000+0100},
  address = {Hingham, MA, USA},
  author = {Lowe, David G.},
  biburl = {https://www.bibsonomy.org/bibtex/2c9984d3a783a48553018a518847f6657/daill},
  description = {Distinctive Image Features from Scale-Invariant Keypoints},
  doi = {10.1023/B:VISI.0000029664.99615.94},
  interhash = {a1c2b94c96ee2ef15ef53e73b7fd9a8d},
  intrahash = {c9984d3a783a48553018a518847f6657},
  issn = {0920-5691},
  issue_date = {November 2004},
  journal = {Int. J. Comput. Vision},
  keywords = {feature sift},
  month = nov,
  number = 2,
  numpages = {20},
  pages = {91--110},
  publisher = {Kluwer Academic Publishers},
  timestamp = {2012-11-08T15:54:11.000+0100},
  title = {Distinctive Image Features from Scale-Invariant Keypoints},
  url = {http://dx.doi.org/10.1023/B:VISI.0000029664.99615.94},
  volume = 60,
  year = 2004
}

@article{Bay:SURF,
  abstract = {This article presents a novel scale- and rotation-invariant detector and descriptor, coined SURF (Speeded-Up Robust Features). SURF approximates or even outperforms previously proposed schemes with respect to repeatability, distinctiveness, and robustness, yet can be computed and compared much faster.

This is achieved by relying on integral images for image convolutions; by building on the strengths of the leading existing detectors and descriptors (specifically, using a Hessian matrix-based measure for the detector, and a distribution-based descriptor); and by simplifying these methods to the essential. This leads to a combination of novel detection, description, and matching steps.

The paper encompasses a detailed description of the detector and descriptor and then explores the effects of the most important parameters. We conclude the article with SURF’s application to two challenging, yet converse goals: camera calibration as a special case of image registration, and object recognition. Our experiments underline SURF’s usefulness in a broad range of topics in computer vision.},
  added-at = {2012-09-30T19:58:26.000+0200},
  author = {Bay, Herbert and Ess, Andreas and Tuytelaars, Tinne and Gool, Luc Van},
  biburl = {https://www.bibsonomy.org/bibtex/2dfea172dfaca0272dcdc66acf92ec58d/daill},
  description = {ScienceDirect.com - Computer Vision and Image Understanding - Speeded-Up Robust Features (SURF)},
  doi = {10.1016/j.cviu.2007.09.014},
  interhash = {befc128dd8bce45a9d0308f72dc9a95a},
  intrahash = {dfea172dfaca0272dcdc66acf92ec58d},
  issn = {1077-3142},
  journal = {Computer Vision and Image Understanding},
  keywords = {detector feature surf},
  note = {Similarity Matching in Computer Vision and Multimedia},
  number = 3,
  pages = {346 - 359},
  timestamp = {2012-09-30T19:58:26.000+0200},
  title = {Speeded-Up Robust Features (SURF)},
  url = {http://www.sciencedirect.com/science/article/pii/S1077314207001555},
  volume = 110,
  year = 2008
}

@InProceedings{Chen:FCNN,
author = {Chen, Qifeng and Xu, Jia and Koltun, Vladlen},
title = {Fast Image Processing With Fully-Convolutional Networks},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
month = {Oct},
year = {2017}
}

@misc{Simonyan:VCC16,
  doi = {10.48550/ARXIV.1409.1556},
  url = {https://arxiv.org/abs/1409.1556},
  author = {Simonyan, Karen and Zisserman, Andrew},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  publisher = {arXiv},
  year = {2014},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{Neubeck:NMS,
  title={Efficient non-maximum suppression},
  author={Neubeck, Alexander and Van Gool, Luc},
  booktitle={18th International Conference on Pattern Recognition (ICPR'06)},
  volume={3},
  pages={850--855},
  year={2006},
  organization={IEEE}
}

@misc{Rezatofighi:IoU,
  doi = {10.48550/ARXIV.1902.09630},
  url = {https://arxiv.org/abs/1902.09630},
  author = {Rezatofighi, Hamid and Tsoi, Nathan and Gwak, JunYoung and Sadeghian, Amir and Reid, Ian and Savarese, Silvio},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Generalized Intersection over Union: A Metric and A Loss for Bounding Box Regression},
  publisher = {arXiv},
  year = {2019},
  copyright = {Creative Commons Attribution Non Commercial Share Alike 4.0 International}
}

@misc{Mojang-Minecraft,
  title        = "Minecraft",
  booktitle    = "Minecraft.net",
  author       = "{Mojang}",
  publisher    = "Microsoft",
  month        =  nov,
  year         =  2011,
  howpublished = "\url{https://www.minecraft.net/en-us}",
}
