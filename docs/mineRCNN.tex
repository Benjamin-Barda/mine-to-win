\documentclass[10pt,journal,cspaper,compsoc]{IEEEtran}
\usepackage[]{lipsum}
\usepackage{cite}
\usepackage{amsmath,amssymb}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{multirow}

\usepackage[aboveskip=8pt]{caption}

\usepackage[dvips]{graphicx}
\DeclareGraphicsExtensions{.pdf}
\usepackage[american]{babel}

\usepackage{tabularx}


\usepackage{url}
\usepackage{cvpr}
\usepackage{multicol}

\usepackage{stfloats}
\usepackage[bookmarks=false,colorlinks=true,linkcolor=black,citecolor=black,filecolor=black,urlcolor=black]{hyperref}

\newcommand{\cb}[1]{\textbf{#1}}
\newcommand{\ct}[1]{\fontsize{7pt}{1pt}\selectfont{#1}}
\newcommand{\tn}[1]{\footnotesize{#1}}
\newcolumntype{x}{>\small c}


\def\cls{\mathit{cls}}
\def\reg{\mathit{reg}}

%\renewcommand{\floatpagefraction}{0.1}
%\renewcommand{\bottomfraction}{0.1}
%\renewcommand{\topfraction}{1}
%\renewcommand{\textfraction}{0.0}
\renewcommand{\dbltopfraction}{1.0}
\renewcommand{\dblfloatpagefraction}{0.0}

\newcommand{\tabincell}[2]{\begin{tabular}{@{}#1@{}}#2\end{tabular}}

\title{Mine-RCNN}

\begin{document}


    \author{Loi~Dario (1940849),
        Marincione~Davide (1927757),
        Barda~Benjamin (1805213)% <-this % stops a space
    }
%\IEEEcompsocitemizethanks{
%\IEEEcompsocthanksitem S. Ren is with University of Science and Technology of China, Hefei, China. This work was done when S. Ren was an intern at Microsoft Research. Email: sqren@mail.ustc.edu.cn
%\IEEEcompsocthanksitem K.~He and J.~Sun are with Visual Computing Group, Microsoft Research. E-mail: \{kahe,jiansun\}@microsoft.com
%\IEEEcompsocthanksitem R.~Girshick is with Facebook AI Research. The majority of this work was done when R. Girshick was with Microsoft Research. E-mail: rbg@fb.com}
%}

\IEEEcompsoctitleabstractindextext{%
\begin{abstract}
    Real time object detection has recently been made possible due to steady state-of-the-art advancements in the field \cite{arxiv:FastRCNN,arxiv:FasterRCNN}, these methods propose the use of a Region Proposal Network to 
    identify Regions of Interest (RoIs) in the image and correctly classify them, we aim to reproduce the architecture proposed by \cite{arxiv:FasterRCNN} applied to a novel environment, that of the
    popular sandbox Minecraft, both for the ease-of-collection of the required data and for a number of graphical properties possesed by the game that make such a complex problem more approachable in terms 
    of computational resources, moreover, due to the novelty of the environment, we also train the entirety of the network from the ground up, having no pre-trained backbone at our disposal.
\end{abstract}

%State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like SPPnet and Fast R-CNN have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck. In this work, we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully convolutional network that simultaneously predicts object bounds and objectness scores at each position. The RPN is trained end-to-end to generate high-quality region proposals, which are used by Fast R-CNN for detection. We further merge RPN and Fast R-CNN into a single network by sharing their convolutional features---using the recently popular terminology of neural networks with 'attention' mechanisms, the RPN component tells the unified network where to look. For the very deep VGG-16 model, our detection system has a frame rate of 5fps (including all steps) on a GPU, while achieving state-of-the-art object detection accuracy on PASCAL VOC 2007, 2012, and MS COCO datasets with only 300 proposals per image. In ILSVRC and COCO 2015 competitions, Faster R-CNN and RPN are the foundations of the 1st-place winning entries in several tracks. Code has been made publicly available.

% Note that keywords are not normally used for peer review papers.
\begin{IEEEkeywords}
 Object Detection, Convolutional Neural Network, Sandbox, Region Proposal, Real Time Detection
\end{IEEEkeywords}}

\maketitle
\IEEEpeerreviewmaketitle
    
    \section{Introduction}
    

    \section{Method}
    \subsection{The Dataset}
    We started first by building the dataset. We recorded one-minutes long videos of minecraft using commercial screen captures softwares. We then loaded those shorts into python, using the OpenCV library, in order to sample one frame per second as we 
    beleived would have given enough time for the next sampled frame to have significative diffrences with respect to the previous ones. We then downsampled the images in order to compress the size of the dataset in order to be able to share it with ease. To further 
    reduce the problem we adopted for the final image a one-to-scale ratio, thus making the image squared. At this time we opted to limit ourselves to only five classes we were aiming to classify: Zombies, Creepers, Pigs, Sheeps, Nothing. 
    The next step was labeling each sampled frames. We developed a simple but effective tool that allowed us to draw boundng boxes(BBox), and assign to each one of them a label corresponding to a class mentioned above. During this process we pruned images that we considered
    unfit to be part of the dataset (e.g. frames inside the game menu or outside of the game). After standardizing the coordinates of BBoxes we saved them into JSONs files. Having our JSONS files ready we group them into a single .dtst file for better integration with the PyTorch
    library, which is the one we decided to use for this project. From the sampling of the images we collected 3920 valid frames. 
    

    \bibliographystyle{IEEEtran}
    \bibliography{ref}

\end{document}
