\documentclass[english]{beamer}
\usepackage[english]{babel}
\usepackage[utf8]{inputenx}
\usepackage[T1]{fontenc}      % Font encoding
\usepackage{lmodern}          % lmodern font, correctly copyable characters in pdf

\usetheme[
  bullet=circle,                  % Use circles instead of squares for bullets
  titleline=false,                % Show a line below the frame
  alternativetitlepage=true,      % Use the fancy title
  titlepagelogo=logo-sapienza,    % Logo for the first slide
  watermark=watermark-diag,   % Watermark used in every slide
  watermarkheight=20px,           % Desired height of the watermark
  watermarkheightmult=6,          % Watermark image is actually x times bigger
  displayauthoronfooter=true,     % Display author name in the footer
]{Roma}
\watermarkoff
\author{Dario Loi, Davide Marincione, Benjamin Barda}
\title{Mine-RPN}
\subtitle{Or how we were able to recognize pigs et. familia in Minecraft}
\institute{Bachelor's degree in\\Applied Computer Science and Artificial Intelligence\\Sapienza, University of Rome}
\date{A. Y. 2021 - 2022}

\begin{document}

\begin{frame}[t,plain]
\titlepage
\end{frame}

\section{Who?}
\begin{frame}{Breaking the ice}
  FACCIAMO QUALCOSA DI SCEMO
\end{frame}
\section{What, why?}
\begin{frame}{Faster RCNN}
	\begin{columns}
	    
	    \begin{column}{0.5\textwidth}
	      Developed in 2015 by Facebook's researches, Faster-RCNN is still today an industry standard thanks to it's accuracy and performance, getting a step closer to real time object detection
	    \end{column}
	
	    \begin{column}{0.5\textwidth}
	      \begin{figure}
	        \centering
	            \includegraphics[width=1.0\textwidth]{../images/rpn_schema.jpeg}
	            \caption{Faster-RCNN architecture.}
	        \end{figure}
	    \end{column}
	  \end{columns}
\end{frame}

\begin{frame}{Why minecraft?}

  \begin{columns}
    
    \begin{column}{0.5\textwidth}
      Minecraft has several desirable qualities:
      \begin{itemize}
        \item Simple graphics.
        \item Sandbox.
        \item Available to every team member.
        \item Distinguishable entity silhouettes.
      \end{itemize}
    \end{column}

    \begin{column}{0.5\textwidth}
      \begin{figure}
        \centering
            \includegraphics[width=1.0\textwidth]{images/minecraft.jpg}
            \caption{A Minecraft promotional image.}
        \end{figure}
    \end{column}

  \end{columns}

\end{frame}

\section{Dataset}
\begin{frame}{Behold, data!}
  \begin{columns}
    \begin{column}{0.5\textwidth}
      4000 images spread across 40 videos!

      How did we collect these videos?
      \begin{itemize}
        \item 1 minute long (circa).
        \item As many biomes as possible.
        \item One mob per video (except test).
      \end{itemize}
    \end{column}

    \begin{column}{0.5\textwidth}
      \begin{figure}[h]
          \centering
          \includegraphics[width=0.9\textwidth]{../images/dtset_repr.png}
          \caption{A representative chunk of our dataset}
      \end{figure}
    \end{column}

  \end{columns}
\end{frame}

\begin{frame}{Augmentation Techniques}
  \begin{columns}
    
    \begin{column}{0.5\textwidth}
      In order to prevent overfitting and increase the amount of information available, we employed various 
      data augmentation techniques, such as:
      \begin{itemize}
        \item Rotation and Reflections.
        \item Adjustments to Contrast, Brightness and Saturation.
        \item Sharpening and Blurring the image.
      \end{itemize}
    \end{column}

    \begin{column}{0.5\textwidth}
      \begin{figure}
        \centering
            \includegraphics[width=1.0\textwidth]{../images/dtset_repr_mod.png}
            \caption{Our Dataset, Augmented.}
        \end{figure}
    \end{column}

  \end{columns}
\end{frame}

\begin{frame}{Tool}
  \begin{columns}
    \begin{column}{0.5\textwidth}
      How to label 4000 images?
      \begin{enumerate}
        \item Load image
        \item Create box / purge
        \item Next
      \end{enumerate}
    \end{column}

    \begin{column}{0.5\textwidth}
      \begin{figure}[h]
        \centering
        \vspace*{-1cm}
        \includegraphics[width=0.9\textwidth]{../images/dataset_tool_show.png}
        \caption{BBoxing in our tool}
      \end{figure}
    \end{column}
  \end{columns}
\end{frame}

\section{Architectures}
\begin{frame}{Our Backbone}
  \begin{columns}
    
    \begin{column}{0.5\textwidth}
      The backbone is the convolutional \emph{heart} of our model, it is:
      \begin{itemize}
        \item Blazingly fast.
        \item Adaptable to any resolution.
      \end{itemize}
      While also offering:
      \begin{itemize}
        \item A 92\% accuracy when used as a Classifier.
        \item A mean training time of $\approx2h$.
      \end{itemize}
    \end{column}

    \begin{column}{0.5\textwidth}
      \begin{figure}
        \centering
            \includegraphics[width=1.0\textwidth]{images/backbone.pdf}
            \caption{Our backbone.}
        \end{figure}
    \end{column}

  \end{columns}
\end{frame}

\begin{frame}{Our RPN}
  \begin{columns}
    
    \begin{column}{0.5\textwidth}
      Our RPN network extends our Backbone and is composed mainly of two twin layers:
      \begin{enumerate}
        \item A Classification layer.
        \item A Regression layer.
      \end{enumerate}
      Before feeding data into those, it also performs some pre-processing:
      \begin{itemize}
        \item Anchor Splashing.
        \item Base convolution.
        \item Flattening (how do we get to fully connected otherwise?)
      \end{itemize}
    \end{column}

    \begin{column}{0.5\textwidth}
      \begin{figure}
        \centering
            \includegraphics[width=1.0\textwidth]{images/network.pdf}
            \caption{Our network's proposal layer.}
        \end{figure}
    \end{column}

  \end{columns}
\end{frame}

\begin{frame}{Our Tricks}

  In order to allow our Backbone and RPN to \emph{punch above their weight}, that is, learn a complex task
  with fewer parameters or with a smaller dataset, we employed two popular regularization techniques:

  \begin{itemize}
    \item Batchnorm.
    A Layer that computes a running $\mu$ and $\sigma^2$, standardizing the input at inference time, this 
    increases capacity.
    \item Dropout.
    A Layer that randomly zeroes out outputs of the preceding layer, adding bagging\footnote{Essentially, simulating an ensemble without performance costs.}
    to our network and making it more robust.
  \end{itemize}

\end{frame}

\section{Results}
\begin{frame}{Examples (1/2)}
	\begin{columns}
	    
	    \begin{column}{0.5\textwidth}

	    Even if many proposal are presented, the network realizes which is the objects to focus on, and which to discard

      It is not always that easy\dots
	
	    \end{column}
	
	    \begin{column}{0.5\textwidth}
	      \begin{figure}
	        \centering
	            \includegraphics[width=1.0\textwidth]{../images/nice_creeper.png}
	            \caption{A creeper in it's natural environment}
	        \end{figure}
	    \end{column}
	  \end{columns}
\end{frame}

\begin{frame}{Examples (2/2)}
	\begin{columns}
	    
	    \begin{column}{0.5\textwidth}
    		\begin{figure}
	    \centering
	    \includegraphics[width=1.0\textwidth]{../images/sunset2.jpeg}
	   \caption{A very confusing sunset\footnote{The issue is talked about in-depth in our paper.}}
		\end{figure}
	    \end{column}
	
	    \begin{column}{0.5\textwidth}
	      \begin{figure}
	        \centering
	            \includegraphics[width=1.0\textwidth]{../images/sunset.png}
	            \caption{The network struggling}
	        \end{figure}
	    \end{column}
	  \end{columns}
\end{frame}


\section{Conclusions}
\begin{frame}{In Conclusion\dots}
	\begin{columns}
	    
	    \begin{column}{0.5\textwidth}
        We believe that, even if the model has its hiccups when presented with weird scenarios, the mere fact of being able to deploy such an architecture
        on a novel dataset, having trained it completely from scratch, is quite a good result.
	    \end{column}
	
	    \begin{column}{0.5\textwidth}
        Most importantly, the model is able to identify objects at inference time at an impressive speed, and, thanks to optimization techniques such as \emph{model freezing}
        and \emph{quantization}, it could be used as a tool for real-time object detection.
	    \end{column}
	  \end{columns}
\end{frame}


\begin{frame}{The End.}

  \begin{columns}
    
    \begin{column}{0.4\textwidth}
      Question Time! (it's an exam after all\dots).
    \end{column}
    
    \begin{column}{0.6\textwidth}
      \begin{figure}
        \centering
            \includegraphics[width=1.0\textwidth]{images/The_End.jpg}
            \caption{The End.}
        \end{figure}
    \end{column}

  \end{columns}

\end{frame}

\end{document}